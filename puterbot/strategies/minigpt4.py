"""
Implements a playback strategy wherein the next InputEvents are generated by showing
ScreenShots and InputEvents to Minigpt-4 and giving it a text description of the goal
to be accomplished.
"""

from pprint import pformat
import time

from loguru import logger
import mss.base

import sys
sys.path.append('../puterbot')
from puterbot.events import get_events
from puterbot.utils import display_event, rows2dicts
from puterbot.models import Recording, Screenshot
from puterbot.strategies.ocr_mixin import OCRReplayStrategyMixin

from MiniGPT4.minigpt4.common.config import Config
from MiniGPT4.minigpt4.common.dist_utils import get_rank
from MiniGPT4.minigpt4.common.registry import registry
from MiniGPT4.minigpt4.conversation.conversation import Chat, CONV_VISION

DISPLAY_EVENTS = False
REPLAY_EVENTS = True
SLEEP = True

from typing import List, Union
import itertools

from loguru import logger
from PIL import Image
from rapidocr_onnxruntime import RapidOCR
from sklearn.cluster import DBSCAN
import numpy as np
import pandas as pd

import argparse
import random

import torch
import torch.backends.cudnn as cudnn


class GPTReplayStrategy(OCRReplayStrategyMixin):

    def __init__(
            self,
            recording: Recording,
            display_events=DISPLAY_EVENTS,
            replay_events=REPLAY_EVENTS,
            sleep=SLEEP,
    ):
        super().__init__(recording)
        self.display_events = display_events
        self.replay_events = replay_events
        self.sleep = sleep
        self.prev_timestamp = None
        self.input_event_idx = -1
        self.processed_input_events = get_events(recording, process=True)
        event_dicts = rows2dicts(self.processed_input_events)
        logger.info(f"event_dicts=\n{pformat(event_dicts)}")

    def get_next_input_event(
            self,
            screenshot: Screenshot,
    ):
        self.input_event_idx += 1
        num_input_events = len(self.processed_input_events)
        if self.input_event_idx >= num_input_events:
            # TODO: refactor
            raise StopIteration()

        # get description of the screenshot using ocr_mixin
        text = self.get_ocr_text(screenshot)

        # get prev InputEvents
        previously_recorded_input_events = ""
        for event in self.processed_input_events[:self.input_event_idx]:
            if previously_recorded_input_events != "":
                previously_recorded_input_events += ", "
            previously_recorded_input_events += event.text

        # feed Recording.task_description, current screenshot, and past InputEvents to
        # MiniGPT4 to generate the next InputEvent
        args = parse_args()
        cfg = Config(args)

        model_config = cfg.model_cfg
        model_config.device_8bit = args.gpu_id
        model_cls = registry.get_model_class(model_config.arch)
        model = model_cls.from_config(model_config).to('cuda:{}'.format(args.gpu_id))

        vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train
        vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(
            vis_processor_cfg)
        chat = Chat(model, vis_processor, device='cuda:{}'.format(args.gpu_id))

        # return MiniGPT4 InputEvent

        # might need to change this part
        input_event = self.processed_input_events[self.input_event_idx]
        logger.info(
            f"{self.input_event_idx=} of {num_input_events=}: {input_event=}"
        )

        # for displaying/replaying events

        if self.display_events:
            image = display_event(input_event)
            image.show()
        if self.replay_events:
            if self.sleep and self.prev_timestamp:
                sleep_time = input_event.timestamp - self.prev_timestamp
                logger.debug(f"{sleep_time=}")
                time.sleep(sleep_time)
            self.prev_timestamp = input_event.timestamp
            return input_event
        else:
            return None


def parse_args():
    parser = argparse.ArgumentParser(description="Demo")
    parser.add_argument("--cfg-path", required=True, help="path to configuration file.")
    parser.add_argument("--gpu-id", type=int, default=0, help="specify the gpu to load the model.")
    parser.add_argument(
        "--options",
        nargs="+",
        help="override some settings in the used config, the key-value pair "
             "in xxx=yyy format will be merged into config file (deprecate), "
             "change to --cfg-options instead.",
    )
    args = parser.parse_args()
    return args


def setup_seeds(config):
    seed = config.run_cfg.seed + get_rank()

    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)

    cudnn.benchmark = False
    cudnn.deterministic = True
